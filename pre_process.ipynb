{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "# function to extract the paths for files froma path\n",
    "def load_paths(data_path):\n",
    "    files = []\n",
    "    files.append(glob.glob(data_path, \n",
    "                recursive = True))\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file exists? False\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "path = \"C:/Users/men22/OneDrive - University of Sussex/FYP/Participants/text/Participant_6/Processed_data/Video/Subject_06_05.mp4\"\n",
    "print(\"file exists?\", os.path.exists(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"C:/Users/men22/OneDrive - University of Sussex/FYP/Participants/notext/\"\n",
    "files = load_paths(data_path + \"*/Processed_data/Video/*.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['C:/Users/men22/OneDrive - University of Sussex/FYP/Participants/notext\\\\Participant_12_no_labels\\\\Processed_data\\\\Video\\\\Subject_12_01.mp4',\n",
       "  'C:/Users/men22/OneDrive - University of Sussex/FYP/Participants/notext\\\\Participant_12_no_labels\\\\Processed_data\\\\Video\\\\Subject_12_02.mp4',\n",
       "  'C:/Users/men22/OneDrive - University of Sussex/FYP/Participants/notext\\\\Participant_12_no_labels\\\\Processed_data\\\\Video\\\\Subject_12_03.mp4',\n",
       "  'C:/Users/men22/OneDrive - University of Sussex/FYP/Participants/notext\\\\Participant_12_no_labels\\\\Processed_data\\\\Video\\\\Subject_12_04.mp4',\n",
       "  'C:/Users/men22/OneDrive - University of Sussex/FYP/Participants/notext\\\\Participant_12_no_labels\\\\Processed_data\\\\Video\\\\Subject_12_05.mp4',\n",
       "  'C:/Users/men22/OneDrive - University of Sussex/FYP/Participants/notext\\\\Participant_12_no_labels\\\\Processed_data\\\\Video\\\\Subject_12_06.mp4',\n",
       "  'C:/Users/men22/OneDrive - University of Sussex/FYP/Participants/notext\\\\Participant_12_no_labels\\\\Processed_data\\\\Video\\\\Subject_12_07.mp4',\n",
       "  'C:/Users/men22/OneDrive - University of Sussex/FYP/Participants/notext\\\\Participant_12_no_labels\\\\Processed_data\\\\Video\\\\Subject_12_08.mp4',\n",
       "  'C:/Users/men22/OneDrive - University of Sussex/FYP/Participants/notext\\\\Participant_12_no_labels\\\\Processed_data\\\\Video\\\\Subject_12_09.mp4',\n",
       "  'C:/Users/men22/OneDrive - University of Sussex/FYP/Participants/notext\\\\Participant_13_no_labels\\\\Processed_data\\\\Video\\\\Subject_13_01.mp4',\n",
       "  'C:/Users/men22/OneDrive - University of Sussex/FYP/Participants/notext\\\\Participant_13_no_labels\\\\Processed_data\\\\Video\\\\Subject_13_02.mp4',\n",
       "  'C:/Users/men22/OneDrive - University of Sussex/FYP/Participants/notext\\\\Participant_13_no_labels\\\\Processed_data\\\\Video\\\\Subject_13_03.mp4',\n",
       "  'C:/Users/men22/OneDrive - University of Sussex/FYP/Participants/notext\\\\Participant_13_no_labels\\\\Processed_data\\\\Video\\\\Subject_13_04.mp4',\n",
       "  'C:/Users/men22/OneDrive - University of Sussex/FYP/Participants/notext\\\\Participant_13_no_labels\\\\Processed_data\\\\Video\\\\Subject_13_05.mp4',\n",
       "  'C:/Users/men22/OneDrive - University of Sussex/FYP/Participants/notext\\\\Participant_13_no_labels\\\\Processed_data\\\\Video\\\\Subject_13_06.mp4',\n",
       "  'C:/Users/men22/OneDrive - University of Sussex/FYP/Participants/notext\\\\Participant_13_no_labels\\\\Processed_data\\\\Video\\\\Subject_13_07.mp4',\n",
       "  'C:/Users/men22/OneDrive - University of Sussex/FYP/Participants/notext\\\\Participant_13_no_labels\\\\Processed_data\\\\Video\\\\Subject_13_08.mp4',\n",
       "  'C:/Users/men22/OneDrive - University of Sussex/FYP/Participants/notext\\\\Participant_13_no_labels\\\\Processed_data\\\\Video\\\\Subject_13_09.mp4',\n",
       "  'C:/Users/men22/OneDrive - University of Sussex/FYP/Participants/notext\\\\Participant_3_no_labels\\\\Processed_data\\\\Video\\\\Subject_03_01.mp4',\n",
       "  'C:/Users/men22/OneDrive - University of Sussex/FYP/Participants/notext\\\\Participant_3_no_labels\\\\Processed_data\\\\Video\\\\Subject_03_01_m.mp4',\n",
       "  'C:/Users/men22/OneDrive - University of Sussex/FYP/Participants/notext\\\\Participant_3_no_labels\\\\Processed_data\\\\Video\\\\Subject_03_02.mp4',\n",
       "  'C:/Users/men22/OneDrive - University of Sussex/FYP/Participants/notext\\\\Participant_3_no_labels\\\\Processed_data\\\\Video\\\\Subject_03_03.mp4',\n",
       "  'C:/Users/men22/OneDrive - University of Sussex/FYP/Participants/notext\\\\Participant_3_no_labels\\\\Processed_data\\\\Video\\\\Subject_03_04.mp4',\n",
       "  'C:/Users/men22/OneDrive - University of Sussex/FYP/Participants/notext\\\\Participant_3_no_labels\\\\Processed_data\\\\Video\\\\Subject_03_05.mp4',\n",
       "  'C:/Users/men22/OneDrive - University of Sussex/FYP/Participants/notext\\\\Participant_3_no_labels\\\\Processed_data\\\\Video\\\\Subject_03_06.mp4',\n",
       "  'C:/Users/men22/OneDrive - University of Sussex/FYP/Participants/notext\\\\Participant_3_no_labels\\\\Processed_data\\\\Video\\\\Subject_03_07.mp4',\n",
       "  'C:/Users/men22/OneDrive - University of Sussex/FYP/Participants/notext\\\\Participant_3_no_labels\\\\Processed_data\\\\Video\\\\Subject_03_08.mp4',\n",
       "  'C:/Users/men22/OneDrive - University of Sussex/FYP/Participants/notext\\\\Participant_3_no_labels\\\\Processed_data\\\\Video\\\\Subject_03_09.mp4',\n",
       "  'C:/Users/men22/OneDrive - University of Sussex/FYP/Participants/notext\\\\Participant_4_no_labels\\\\Processed_data\\\\Video\\\\Subject_04_01.mp4',\n",
       "  'C:/Users/men22/OneDrive - University of Sussex/FYP/Participants/notext\\\\Participant_4_no_labels\\\\Processed_data\\\\Video\\\\Subject_04_02.mp4',\n",
       "  'C:/Users/men22/OneDrive - University of Sussex/FYP/Participants/notext\\\\Participant_4_no_labels\\\\Processed_data\\\\Video\\\\Subject_04_03.mp4',\n",
       "  'C:/Users/men22/OneDrive - University of Sussex/FYP/Participants/notext\\\\Participant_4_no_labels\\\\Processed_data\\\\Video\\\\Subject_04_04.mp4',\n",
       "  'C:/Users/men22/OneDrive - University of Sussex/FYP/Participants/notext\\\\Participant_4_no_labels\\\\Processed_data\\\\Video\\\\Subject_04_05.mp4',\n",
       "  'C:/Users/men22/OneDrive - University of Sussex/FYP/Participants/notext\\\\Participant_4_no_labels\\\\Processed_data\\\\Video\\\\Subject_04_06.mp4',\n",
       "  'C:/Users/men22/OneDrive - University of Sussex/FYP/Participants/notext\\\\Participant_4_no_labels\\\\Processed_data\\\\Video\\\\Subject_04_07.mp4',\n",
       "  'C:/Users/men22/OneDrive - University of Sussex/FYP/Participants/notext\\\\Participant_4_no_labels\\\\Processed_data\\\\Video\\\\Subject_04_08.mp4',\n",
       "  'C:/Users/men22/OneDrive - University of Sussex/FYP/Participants/notext\\\\Participant_4_no_labels\\\\Processed_data\\\\Video\\\\Subject_04_09.mp4',\n",
       "  'C:/Users/men22/OneDrive - University of Sussex/FYP/Participants/notext\\\\Participant_5_no_labels\\\\Processed_data\\\\Video\\\\Subject_05_01.mp4',\n",
       "  'C:/Users/men22/OneDrive - University of Sussex/FYP/Participants/notext\\\\Participant_5_no_labels\\\\Processed_data\\\\Video\\\\Subject_05_02.mp4',\n",
       "  'C:/Users/men22/OneDrive - University of Sussex/FYP/Participants/notext\\\\Participant_5_no_labels\\\\Processed_data\\\\Video\\\\Subject_05_03.mp4',\n",
       "  'C:/Users/men22/OneDrive - University of Sussex/FYP/Participants/notext\\\\Participant_5_no_labels\\\\Processed_data\\\\Video\\\\Subject_05_04.mp4',\n",
       "  'C:/Users/men22/OneDrive - University of Sussex/FYP/Participants/notext\\\\Participant_5_no_labels\\\\Processed_data\\\\Video\\\\Subject_05_05.mp4',\n",
       "  'C:/Users/men22/OneDrive - University of Sussex/FYP/Participants/notext\\\\Participant_5_no_labels\\\\Processed_data\\\\Video\\\\Subject_05_06.mp4',\n",
       "  'C:/Users/men22/OneDrive - University of Sussex/FYP/Participants/notext\\\\Participant_5_no_labels\\\\Processed_data\\\\Video\\\\Subject_05_07.mp4',\n",
       "  'C:/Users/men22/OneDrive - University of Sussex/FYP/Participants/notext\\\\Participant_5_no_labels\\\\Processed_data\\\\Video\\\\Subject_05_08.mp4',\n",
       "  'C:/Users/men22/OneDrive - University of Sussex/FYP/Participants/notext\\\\Participant_5_no_labels\\\\Processed_data\\\\Video\\\\Subject_05_09.mp4',\n",
       "  'C:/Users/men22/OneDrive - University of Sussex/FYP/Participants/notext\\\\Participant_5_no_labels\\\\Processed_data\\\\Video\\\\Subject_05_extra_1.mp4',\n",
       "  'C:/Users/men22/OneDrive - University of Sussex/FYP/Participants/notext\\\\Participant_5_no_labels\\\\Processed_data\\\\Video\\\\Subject_05_extra_2.mp4']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "import random\n",
    "import string\n",
    "\n",
    "def detect_text_change(video_path, save_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    fg_bg = cv2.createBackgroundSubtractorMOG2()\n",
    "    text_on = False\n",
    "    count = 0\n",
    "    current_text = \"\"\n",
    "    out = None\n",
    "    videos = []\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        fg_mask = fg_bg.apply(frame)\n",
    "        white_pixels = cv2.countNonZero(fg_mask[200:, -200:])\n",
    "        \n",
    "        # if white_pixels > 0 and not text_on:\n",
    "        #     text_on = True\n",
    "        #     text = ''\n",
    "        #     text += \" \" + pytesseract.image_to_string(frame[400:, 900:])\n",
    "        #     current_text = text.strip()\n",
    "        #     out = cv2.VideoWriter(f\"{save_path}/{current_text}.avi\", cv2.VideoWriter_fourcc(*\"MJPG\"), 30.0, (frame.shape[1], frame.shape[0]))\n",
    "        #     print(f\"Text {current_text} on\")\n",
    "        #     start_frame = int(cap.get(cv2.CAP_PROP_POS_FRAMES))\n",
    "        \n",
    "        # if white_pixels == 0 and text_on:\n",
    "        #     text_on = False\n",
    "        #     out.release()\n",
    "        #     print(f\"Text {current_text} off\")\n",
    "        #     end_frame = int(cap.get(cv2.CAP_PROP_POS_FRAMES)) - 1\n",
    "        #     videos.append((start_frame, end_frame))\n",
    "\n",
    "        if white_pixels > 0 and not text_on:\n",
    "            text_on = True\n",
    "            text = ''\n",
    "            text += \" \" + pytesseract.image_to_string(frame[400:, 900:])\n",
    "            current_text = text.strip()\n",
    "            # first word\n",
    "            if out is None:\n",
    "                # if the word is not recognised then name the video with a random letter\n",
    "                # if current_text == '':\n",
    "                #     current_text=''.join(random.choice(string.ascii_lowercase))\n",
    "                    # write out\n",
    "                if current_text == '':\n",
    "                    #     current_text=''.join(random.choice(string.ascii_lowercase))\n",
    "                    add_text = ''.join(random.choice(string.ascii_lowercase))\n",
    "                    out = cv2.VideoWriter(f\"{save_path}/{current_text + add_text}.avi\", cv2.VideoWriter_fourcc(*\"MJPG\"), 30.0, (frame.shape[1], frame.shape[0]))\n",
    "\n",
    "                else: out = cv2.VideoWriter(f\"{save_path}/{current_text}.avi\", cv2.VideoWriter_fourcc(*\"MJPG\"), 30.0, (frame.shape[1], frame.shape[0]))\n",
    "                print('out is None')\n",
    "            # elif current_text == prev_text:\n",
    "\n",
    "            else:\n",
    "                if current_text != prev_text:\n",
    "                    out.release()\n",
    "                    if current_text == '':\n",
    "                    #     current_text=''.join(random.choice(string.ascii_lowercase))\n",
    "                        add_text = ''.join(random.choice(string.ascii_lowercase))\n",
    "                        out = cv2.VideoWriter(f\"{save_path}/{current_text + add_text}.avi\", cv2.VideoWriter_fourcc(*\"MJPG\"), 30.0, (frame.shape[1], frame.shape[0]))\n",
    "\n",
    "                    else: out = cv2.VideoWriter(f\"{save_path}/{current_text}.avi\", cv2.VideoWriter_fourcc(*\"MJPG\"), 30.0, (frame.shape[1], frame.shape[0]))\n",
    "                    print('current_text != prev')\n",
    "                print('else')\n",
    "            prev_text = current_text\n",
    "            print(f\"Text {current_text} on\")\n",
    "            start_frame = int(cap.get(cv2.CAP_PROP_POS_FRAMES))\n",
    "        \n",
    "        if white_pixels == 0 and text_on:\n",
    "            text_on = False\n",
    "            out.release()\n",
    "            print(f\"Text {current_text} off\")\n",
    "            # end_frame = int(cap.get(cv2.CAP_PROP_POS_FRAMES)) - 1\n",
    "            end_frame = int(cap.get(cv2.CAP_PROP_POS_FRAMES)) - 1\n",
    "            if current_text == '':\n",
    "                videos.append((current_text + add_text, start_frame, end_frame))\n",
    "                # add_text = ''\n",
    "            else: videos.append((current_text, start_frame, end_frame))\n",
    "        \n",
    "        if text_on:\n",
    "            out.write(frame)\n",
    "            \n",
    "        cv2.imshow('Frame', frame)\n",
    "        cv2.imshow('FG Mask', fg_mask)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    return videos\n",
    "\n",
    "\n",
    "\n",
    "# def detect_text_change(video_path, save_path):\n",
    "#     cap = cv2.VideoCapture(video_path)\n",
    "#     fg_bg = cv2.createBackgroundSubtractorMOG2()\n",
    "#     text_on = False\n",
    "#     current_text = \"\"\n",
    "#     out = None\n",
    "#     videos = []\n",
    "\n",
    "#     while True:\n",
    "#         ret, frame = cap.read()\n",
    "#         if not ret:\n",
    "#             break\n",
    "\n",
    "#         fg_mask = fg_bg.apply(frame)\n",
    "#         white_pixels = cv2.countNonZero(fg_mask[200:, -200:])\n",
    "\n",
    "#         if white_pixels > 0 and not text_on:\n",
    "#             text_on = True\n",
    "#             text = ''\n",
    "#             text += \" \" + pytesseract.image_to_string(frame[400:, 900:])\n",
    "#             current_text = text.strip()\n",
    "#             if out is None:\n",
    "#                 out = cv2.VideoWriter(f\"{save_path}/{current_text}.avi\", cv2.VideoWriter_fourcc(*\"MJPG\"), 30.0, (frame.shape[1], frame.shape[0]))\n",
    "#                 start_frame = int(cap.get(cv2.CAP_PROP_POS_FRAMES))\n",
    "#             else:\n",
    "#                 if current_text != prev_text:\n",
    "#                     out.release()\n",
    "#                     end_frame = int(cap.get(cv2.CAP_PROP_POS_FRAMES)) - 1\n",
    "#                     videos.append((start_frame, end_frame))\n",
    "#                     start_frame = int(cap.get(cv2.CAP_PROP_POS_FRAMES))\n",
    "#                     out = cv2.VideoWriter(f\"{save_path}/{current_text}.avi\", cv2.VideoWriter_fourcc(*\"MJPG\"), 30.0, (frame.shape[1], frame.shape[0]))\n",
    "#             prev_text = current_text\n",
    "#             print(f\"Text {current_text} on\")\n",
    "\n",
    "#         if white_pixels == 0 and text_on:\n",
    "#             text_on = False\n",
    "#             out.release()\n",
    "#             end_frame = int(cap.get(cv2.CAP_PROP_POS_FRAMES)) - 1\n",
    "#             videos.append((start_frame, end_frame))\n",
    "#             print(f\"Text {current_text} off\")\n",
    "\n",
    "#         if text_on:\n",
    "#             out.write(frame)\n",
    "\n",
    "#         cv2.imshow('Frame', frame)\n",
    "#         cv2.imshow('FG Mask', fg_mask)\n",
    "#         if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#             break\n",
    "\n",
    "#     cap.release()\n",
    "#     cv2.destroyAllWindows()\n",
    "#     return videos\n",
    "\n",
    "\n",
    "\n",
    "# def detect_text_change(video_path, save_path):\n",
    "#     cap = cv2.VideoCapture(video_path)\n",
    "#     fg_bg = cv2.createBackgroundSubtractorMOG2()\n",
    "#     text_on = False\n",
    "#     count = 0\n",
    "#     current_text = \"\"\n",
    "#     out = None\n",
    "#     videos = []\n",
    "\n",
    "#     while True:\n",
    "#         ret, frame = cap.read()\n",
    "#         if not ret:\n",
    "#             break\n",
    "\n",
    "#         fg_mask = fg_bg.apply(frame)\n",
    "#         white_pixels = cv2.countNonZero(fg_mask[200:, -200:])\n",
    "#         cv2.imshow(fg_mask[200:, -200:])    \n",
    "\n",
    "#         if white_pixels > 0 and not text_on:\n",
    "#             text_on = True\n",
    "#             text = ''\n",
    "#             text += \" \" + pytesseract.image_to_string(frame[400:, 900:])\n",
    "#             current_text = text.strip()\n",
    "#             if out is None:\n",
    "#                 out = cv2.VideoWriter(f\"{save_path}/{current_text}.avi\", cv2.VideoWriter_fourcc(*\"MJPG\"), 30.0, (frame.shape[1], frame.shape[0]))\n",
    "#             else:\n",
    "#                 if current_text != prev_text:\n",
    "#                     out.release()\n",
    "#                     end_frame = int(cap.get(cv2.CAP_PROP_POS_FRAMES)) - 1\n",
    "#                     videos.append((start_frame, end_frame))\n",
    "#                     start_frame = int(cap.get(cv2.CAP_PROP_POS_FRAMES))\n",
    "#                     out = cv2.VideoWriter(f\"{save_path}/{current_text}.avi\", cv2.VideoWriter_fourcc(*\"MJPG\"), 30.0, (frame.shape[1], frame.shape[0]))\n",
    "#             prev_text = current_text\n",
    "#             print(f\"Text {current_text} on\")\n",
    "#             start_frame = int(cap.get(cv2.CAP_PROP_POS_FRAMES))\n",
    "        \n",
    "#         if white_pixels == 0 and text_on:\n",
    "#             text_on = False\n",
    "#             out.release()\n",
    "#             end_frame = int(cap.get(cv2.CAP_PROP_POS_FRAMES)) - 1\n",
    "#             videos.append((start_frame, end_frame))\n",
    "#             print(f\"Text {current_text} off\")\n",
    "        \n",
    "#         if text_on:\n",
    "#             out.write(frame)\n",
    "            \n",
    "#         cv2.imshow('Frame', frame)\n",
    "#         cv2.imshow('FG Mask', fg_mask)\n",
    "#         if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#             break\n",
    "\n",
    "#     cap.release()\n",
    "#     cv2.destroyAllWindows()\n",
    "#     return videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "\n",
    "def detect_text_change(video_path, save_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    fg_bg = cv2.createBackgroundSubtractorMOG2()\n",
    "    text_on = False\n",
    "    count = 0\n",
    "    current_text = \"\"\n",
    "    prev_text = \"\"\n",
    "    out = None\n",
    "    videos = []\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        fg_mask = fg_bg.apply(frame)\n",
    "        white_pixels = cv2.countNonZero(fg_mask[200:, -200:])\n",
    "\n",
    "        if white_pixels > 0 and not text_on:\n",
    "            text_on = True\n",
    "            text = ''\n",
    "            text += \" \" + pytesseract.image_to_string(frame[400:, 900:])\n",
    "            current_text = text.strip()\n",
    "            # if out is None:\n",
    "            #     out = cv2.VideoWriter(f\"{save_path}/{current_text}.avi\", cv2.VideoWriter_fourcc(*\"MJPG\"), 30.0, (frame.shape[1], frame.shape[0]))\n",
    "            # else:\n",
    "            if current_text != prev_text:\n",
    "                    out.release()\n",
    "                    out = cv2.VideoWriter(f\"{save_path}/{current_text}.avi\", cv2.VideoWriter_fourcc(*\"MJPG\"), 30.0, (frame.shape[1], frame.shape[0]))\n",
    "            # elif out is None:\n",
    "            #     out = cv2.VideoWriter(f\"{save_path}/{current_text}.avi\", cv2.VideoWriter_fourcc(*\"MJPG\"), 30.0, (frame.shape[1], frame.shape[0]))\n",
    "            prev_text = current_text\n",
    "            if out is None:\n",
    "                out = cv2.VideoWriter(f\"{save_path}/{current_text}.avi\", cv2.VideoWriter_fourcc(*\"MJPG\"), 30.0, (frame.shape[1], frame.shape[0]))\n",
    "            print(f\"Text {current_text} on\")\n",
    "            start_frame = int(cap.get(cv2.CAP_PROP_POS_FRAMES))\n",
    "\n",
    "        if white_pixels == 0 and text_on:\n",
    "            text_on = False\n",
    "            out.release()\n",
    "            print(f\"Text {current_text} off\")\n",
    "            end_frame = int(cap.get(cv2.CAP_PROP_POS_FRAMES)) - 1\n",
    "            videos.append((current_text, start_frame, end_frame))\n",
    "            current_text = \"\"\n",
    "            prev_text = \"\"\n",
    "\n",
    "        if text_on:\n",
    "            out.write(frame)\n",
    "\n",
    "        cv2.imshow('Frame', frame)\n",
    "        cv2.imshow('FG Mask', fg_mask)\n",
    "        cv2.imshow('fg cut', fg_mask[200:, -200:])\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    return videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out is None\n",
      "Text  on\n",
      "Text  off\n",
      "else\n",
      "Text  on\n",
      "Text  off\n",
      "current_text != prev\n",
      "else\n",
      "Text Pen on\n",
      "Text Pen off\n",
      "else\n",
      "Text Pen on\n",
      "Text Pen off\n",
      "current_text != prev\n",
      "else\n",
      "Text Bigail on\n",
      "Text Bigail off\n",
      "else\n",
      "Text Bigail on\n",
      "Text Bigail off\n",
      "current_text != prev\n",
      "else\n",
      "Text  on\n",
      "Text  off\n",
      "current_text != prev\n",
      "else\n",
      "Text Desg on\n",
      "Text Desg off\n",
      "else\n",
      "Text Desg on\n",
      "Text Desg off\n",
      "current_text != prev\n",
      "else\n",
      "Text Cath on\n",
      "Text Cath off\n",
      "current_text != prev\n",
      "else\n",
      "Text Galw on\n",
      "Text Galw off\n",
      "else\n",
      "Text Galw on\n",
      "Text Galw off\n",
      "current_text != prev\n",
      "else\n",
      "Text Ffair on\n",
      "Text Ffair off\n",
      "else\n",
      "Text Ffair on\n",
      "Text Ffair off\n",
      "current_text != prev\n",
      "else\n",
      "Text Faint on\n",
      "Text Faint off\n",
      "else\n",
      "Text Faint on\n",
      "Text Faint off\n",
      "current_text != prev\n",
      "else\n",
      "Text Theatr on\n",
      "Text Theatr off\n",
      "else\n",
      "Text Theatr on\n",
      "Text Theatr off\n",
      "current_text != prev\n",
      "else\n",
      "Text DY s fer) on\n",
      "Text DY s fer) off\n",
      "current_text != prev\n",
      "else\n",
      "Text  on\n",
      "Text  off\n",
      "else\n",
      "Text  on\n",
      "Text  off\n",
      "else\n",
      "Text  on\n",
      "Text  off\n",
      "current_text != prev\n",
      "else\n",
      "Text Llaw on\n",
      "Text Llaw off\n",
      "else\n",
      "Text Llaw on\n",
      "Text Llaw off\n",
      "current_text != prev\n",
      "else\n",
      "Text Siop on\n",
      "Text Siop off\n",
      "current_text != prev\n",
      "else\n",
      "Text Chi on\n",
      "Text Chi off\n",
      "else\n",
      "Text Chi on\n",
      "Text Chi off\n",
      "else\n",
      "Text Chi on\n",
      "Text Chi off\n",
      "current_text != prev\n",
      "else\n",
      "Text Het on\n",
      "Text Het off\n",
      "else\n",
      "Text Het on\n",
      "Text Het off\n",
      "current_text != prev\n",
      "else\n",
      "Text Cwtsh on\n",
      "Text Cwtsh off\n",
      "current_text != prev\n",
      "else\n",
      "Text Jam on\n",
      "Text Jam off\n",
      "else\n",
      "Text Jam on\n",
      "Text Jam off\n",
      "current_text != prev\n",
      "else\n",
      "Text Rhaw on\n",
      "Text Rhaw off\n",
      "else\n",
      "Text Rhaw on\n",
      "Text Rhaw off\n",
      "current_text != prev\n",
      "else\n",
      "Text sXeloleya on\n",
      "Text sXeloleya off\n",
      "else\n",
      "Text sXeloleya on\n",
      "Text sXeloleya off\n",
      "current_text != prev\n",
      "else\n",
      "Text Lamp on\n",
      "Text Lamp off\n",
      "else\n",
      "Text Lamp on\n",
      "Text Lamp off\n",
      "current_text != prev\n",
      "else\n",
      "Text Mawr on\n",
      "Text Mawr off\n",
      "else\n",
      "Text Mawr on\n",
      "Text Mawr off\n",
      "current_text != prev\n",
      "else\n",
      "Text Neidr on\n",
      "Text Neidr off\n",
      "else\n",
      "Text Neidr on\n",
      "Text Neidr off\n",
      "current_text != prev\n",
      "else\n",
      "Text Cyngor on\n",
      "Text Cyngor off\n",
      "else\n",
      "Text Cyngor on\n",
      "Text Cyngor off\n",
      "current_text != prev\n",
      "else\n",
      "Text laith on\n",
      "Text laith off\n",
      "else\n",
      "Text laith on\n",
      "Text laith off\n",
      "current_text != prev\n",
      "else\n",
      "Text Wedyn on\n",
      "Text Wedyn off\n",
      "else\n",
      "Text Wedyn on\n",
      "Text Wedyn off\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('r', 1, 1),\n",
       " ('r', 31, 37),\n",
       " ('Pen', 106, 176),\n",
       " ('Pen', 200, 222),\n",
       " ('Bigail', 277, 351),\n",
       " ('Bigail', 372, 394),\n",
       " ('l', 468, 585),\n",
       " ('Desg', 639, 718),\n",
       " ('Desg', 733, 755),\n",
       " ('Cath', 821, 938),\n",
       " ('Galw', 987, 1061),\n",
       " ('Galw', 1082, 1104),\n",
       " ('Ffair', 1185, 1262),\n",
       " ('Ffair', 1279, 1301),\n",
       " ('Faint', 1365, 1442),\n",
       " ('Faint', 1460, 1482),\n",
       " ('Theatr', 1549, 1624),\n",
       " ('Theatr', 1644, 1666),\n",
       " ('DY s fer)', 1725, 1842),\n",
       " ('n', 1897, 1974),\n",
       " ('n', 1981, 1983),\n",
       " ('n', 1992, 2014),\n",
       " ('Llaw', 2073, 2154),\n",
       " ('Llaw', 2168, 2190),\n",
       " ('Siop', 2266, 2383),\n",
       " ('Chi', 2438, 2514),\n",
       " ('Chi', 2521, 2521),\n",
       " ('Chi', 2533, 2555),\n",
       " ('Het', 2629, 2719),\n",
       " ('Het', 2724, 2746),\n",
       " ('Cwtsh', 2802, 2919),\n",
       " ('Jam', 2976, 3052),\n",
       " ('Jam', 3071, 3093),\n",
       " ('Rhaw', 3170, 3246),\n",
       " ('Rhaw', 3265, 3287),\n",
       " ('sXeloleya', 3350, 3424),\n",
       " ('sXeloleya', 3445, 3467),\n",
       " ('Lamp', 3527, 3620),\n",
       " ('Lamp', 3622, 3644),\n",
       " ('Mawr', 3698, 3775),\n",
       " ('Mawr', 3793, 3815),\n",
       " ('Neidr', 3888, 3963),\n",
       " ('Neidr', 3983, 4005),\n",
       " ('Cyngor', 4070, 4162),\n",
       " ('Cyngor', 4165, 4187),\n",
       " ('laith', 4252, 4344),\n",
       " ('laith', 4347, 4369),\n",
       " ('Wedyn', 4428, 4504),\n",
       " ('Wedyn', 4523, 4545)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"C:/Users/men22/OneDrive - University of Sussex/FYP/Participants/text/Participant_10/Processed_data/Video/Subject_10_05.mp4\"\n",
    "save = \"C:/Users/men22/Documents/Videos3/\"\n",
    "stamps = detect_text_change(path, save)\n",
    "stamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('r', 1, 1),\n",
       " ('r', 31, 37),\n",
       " ('Pen', 106, 176),\n",
       " ('Pen', 200, 222),\n",
       " ('Bigail', 277, 351),\n",
       " ('Bigail', 372, 394),\n",
       " ('l', 468, 585),\n",
       " ('Desg', 639, 718),\n",
       " ('Desg', 733, 755),\n",
       " ('Cath', 821, 938),\n",
       " ('Galw', 987, 1061),\n",
       " ('Galw', 1082, 1104),\n",
       " ('Ffair', 1185, 1262),\n",
       " ('Ffair', 1279, 1301),\n",
       " ('Faint', 1365, 1442),\n",
       " ('Faint', 1460, 1482),\n",
       " ('Theatr', 1549, 1624),\n",
       " ('Theatr', 1644, 1666),\n",
       " ('DY s fer)', 1725, 1842),\n",
       " ('n', 1897, 1974),\n",
       " ('n', 1981, 1983),\n",
       " ('n', 1992, 2014),\n",
       " ('Llaw', 2073, 2154),\n",
       " ('Llaw', 2168, 2190),\n",
       " ('Siop', 2266, 2383),\n",
       " ('Chi', 2438, 2514),\n",
       " ('Chi', 2521, 2521),\n",
       " ('Chi', 2533, 2555),\n",
       " ('Het', 2629, 2719),\n",
       " ('Het', 2724, 2746),\n",
       " ('Cwtsh', 2802, 2919),\n",
       " ('Jam', 2976, 3052),\n",
       " ('Jam', 3071, 3093),\n",
       " ('Rhaw', 3170, 3246),\n",
       " ('Rhaw', 3265, 3287),\n",
       " ('sXeloleya', 3350, 3424),\n",
       " ('sXeloleya', 3445, 3467),\n",
       " ('Lamp', 3527, 3620),\n",
       " ('Lamp', 3622, 3644),\n",
       " ('Mawr', 3698, 3775),\n",
       " ('Mawr', 3793, 3815),\n",
       " ('Neidr', 3888, 3963),\n",
       " ('Neidr', 3983, 4005),\n",
       " ('Cyngor', 4070, 4162),\n",
       " ('Cyngor', 4165, 4187),\n",
       " ('laith', 4252, 4344),\n",
       " ('laith', 4347, 4369),\n",
       " ('Wedyn', 4428, 4504),\n",
       " ('Wedyn', 4523, 4545)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_segments2(video_path, segments, output_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    stamps1 = segments\n",
    "\n",
    "    # define video writer\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = None\n",
    "\n",
    "    # for i, segment in enumerate(segments):\n",
    "    #     start_frame, end_frame = segment\n",
    "    #     if end_frame-start_frame<=3:break\n",
    "\n",
    "    #     # check if difference between start and end frame is less than 25\n",
    "    #     if out is not None and start_frame - last_end_frame <= 30:\n",
    "    #         # join current segment to previous segment\n",
    "    #         out.release()\n",
    "    #         out = None\n",
    "    #         segments[i] = (last_start_frame, end_frame)\n",
    "    #         continue\n",
    "    #     if out is not None and i+1 < len(segments) and segments[i+1][0] - segments[i+1][1] <= 30: \n",
    "    #         # join current segment to previous segment\n",
    "    #         out.release()\n",
    "    #         out = None\n",
    "    #         segments[i] = (last_start_frame, segments[i+1][1])\n",
    "    #         segments.pop(i+1)\n",
    "    #         continue\n",
    "\n",
    "\n",
    "    for i, segment in enumerate(segments):\n",
    "        current_text, start_frame, end_frame = segment\n",
    "        # if end_frame-start_frame<=3:break\n",
    "\n",
    "        # check if difference between start and end frame is less than 25\n",
    "        if out is not None and prev_text == current_text:\n",
    "            # join current segment to previous segment\n",
    "            out.release()\n",
    "            out = None\n",
    "            segments[i] = (current_text, last_start_frame, end_frame)\n",
    "            if i+1 < len(segments) and segments[i+1][0] == current_text: \n",
    "                segments[i] = (current_text, last_start_frame, segments[i+1][2])\n",
    "                segments.pop(i+1)\n",
    "            continue\n",
    "\n",
    "\n",
    "        # extract video segment\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
    "        out = cv2.VideoWriter(f\"{output_path}/segment_{current_text}.mp4\", fourcc, 30, (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))))\n",
    "        for frame_idx in range(start_frame, end_frame+1):\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            out.write(frame)\n",
    "\n",
    "        last_start_frame, last_end_frame, prev_text = start_frame, end_frame, current_text\n",
    "        out.release()\n",
    "\n",
    "    cap.release()\n",
    "    return stamps1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_segments3(video_path, segments, output_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    # define video writer\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = []\n",
    "\n",
    "    for i, segment in enumerate(segments):\n",
    "        start_frame, end_frame = segment\n",
    "\n",
    "        # check if difference between start and end frame is less than 30\n",
    "        if out and start_frame - last_end_frame <= 30:\n",
    "            # join current segment to previous segment\n",
    "            out[-1].release()\n",
    "            out.pop()\n",
    "            segments[i] = (last_start_frame, end_frame)\n",
    "            continue\n",
    "\n",
    "        # check if difference between current segment and next segment is less than 30\n",
    "        if i + 1 < len(segments):\n",
    "            next_start_frame, next_end_frame = segments[i+1]\n",
    "            if next_start_frame - end_frame <= 30:\n",
    "                # join current segment and next segment\n",
    "                out[-1].release()\n",
    "                out.pop()\n",
    "                segments[i] = (start_frame, next_end_frame)\n",
    "                continue\n",
    "\n",
    "        # check if difference between current segment and the segment after next is less than 30\n",
    "        if i + 2 < len(segments):\n",
    "            next_next_start_frame, next_next_end_frame = segments[i+2]\n",
    "            if next_next_start_frame - end_frame <= 30:\n",
    "                # join current segment, next segment, and segment after next\n",
    "                out[-1].release()\n",
    "                out.pop()\n",
    "                segments[i] = (start_frame, next_next_end_frame)\n",
    "                segments.pop(i+1)\n",
    "                continue\n",
    "\n",
    "        # extract video segment\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
    "        out.append(cv2.VideoWriter(f\"{output_path}/segment_{i}.mp4\", fourcc, 30, (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)))))\n",
    "        for frame_idx in range(start_frame, end_frame+1):\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            out[-1].write(frame)\n",
    "\n",
    "        last_start_frame, last_end_frame = start_frame, end_frame\n",
    "        out[-1].release()\n",
    "\n",
    "    cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_segments3(video_path, segments, output_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    # define video writer\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = None\n",
    "\n",
    "    for i, segment in enumerate(segments):\n",
    "        start_frame, end_frame = segment\n",
    "\n",
    "        # check if difference between start and end frame is less than 30 for two segments\n",
    "        if out is not None and i+1 < len(segments) and start_frame - last_end_frame <= 30 and segments[i+1][1] - start_frame <= 30:\n",
    "            # join current segment and next segment\n",
    "            out.release()\n",
    "            out = None\n",
    "            segments[i] = (last_start_frame, segments[i+1][1])\n",
    "            segments.pop(i+1)\n",
    "            continue\n",
    "\n",
    "        # extract video segment\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
    "        out = cv2.VideoWriter(f\"{output_path}/segment_{i}.mp4\", fourcc, 30, (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))))\n",
    "        for frame_idx in range(start_frame, end_frame+1):\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            out.write(frame)\n",
    "\n",
    "        last_start_frame, last_end_frame = start_frame, end_frame\n",
    "        out.release()\n",
    "\n",
    "    cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('r', 1, 1),\n",
       " ('r', 1, 37),\n",
       " ('Pen', 106, 176),\n",
       " ('Pen', 106, 222),\n",
       " ('Bigail', 277, 351),\n",
       " ('Bigail', 277, 394),\n",
       " ('l', 468, 585),\n",
       " ('Desg', 639, 718),\n",
       " ('Desg', 639, 755),\n",
       " ('Cath', 821, 938),\n",
       " ('Galw', 987, 1061),\n",
       " ('Galw', 987, 1104),\n",
       " ('Ffair', 1185, 1262),\n",
       " ('Ffair', 1185, 1301),\n",
       " ('Faint', 1365, 1442),\n",
       " ('Faint', 1365, 1482),\n",
       " ('Theatr', 1549, 1624),\n",
       " ('Theatr', 1549, 1666),\n",
       " ('DY s fer)', 1725, 1842),\n",
       " ('n', 1897, 1974),\n",
       " ('n', 1897, 2014),\n",
       " ('Llaw', 2073, 2154),\n",
       " ('Llaw', 2073, 2190),\n",
       " ('Siop', 2266, 2383),\n",
       " ('Chi', 2438, 2514),\n",
       " ('Chi', 2438, 2555),\n",
       " ('Het', 2629, 2719),\n",
       " ('Het', 2629, 2746),\n",
       " ('Cwtsh', 2802, 2919),\n",
       " ('Jam', 2976, 3052),\n",
       " ('Jam', 2976, 3093),\n",
       " ('Rhaw', 3170, 3246),\n",
       " ('Rhaw', 3170, 3287),\n",
       " ('sXeloleya', 3350, 3424),\n",
       " ('sXeloleya', 3350, 3467),\n",
       " ('Lamp', 3527, 3620),\n",
       " ('Lamp', 3527, 3644),\n",
       " ('Mawr', 3698, 3775),\n",
       " ('Mawr', 3698, 3815),\n",
       " ('Neidr', 3888, 3963),\n",
       " ('Neidr', 3888, 4005),\n",
       " ('Cyngor', 4070, 4162),\n",
       " ('Cyngor', 4070, 4187),\n",
       " ('laith', 4252, 4344),\n",
       " ('laith', 4252, 4369),\n",
       " ('Wedyn', 4428, 4504),\n",
       " ('Wedyn', 4428, 4545)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"C:/Users/men22/OneDrive - University of Sussex/FYP/Participants/text/Participant_9/Processed_data/Video/Subject_09_05.mp4\"\n",
    "save = \"C:/Users/men22/Documents/Videos3/\"\n",
    "segemnts = extract_segments2(path, stamps, save)\n",
    "segemnts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fyp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
